{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c87b1d94-3737-4f2d-90ba-af29ca325003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUST PROVIDE THIS\n",
    "\n",
    "name_of_experiment = \"test_exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7408cb7-734f-4be0-aa92-ef390f4cadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, emoji\n",
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "# import ipywidgets as widgets\n",
    "import openai\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "import json\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY_MICHAEL\")\n",
    "\n",
    "from prompt_template import create_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe277e87-c934-4d69-a42a-a51b3323a911",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Change the prompt accprding to your need\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d750027c-b5f3-4b03-a522-76a32f8740e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Here you load a dataframe that you have preprocessed to have the following structure\n",
    "\n",
    "How the dataframe must look like \n",
    "it must have a text column and a label column and it must have string as label.\n",
    "\n",
    "\n",
    "test_dataframe_working_with = \n",
    "\n",
    "============================================================================\n",
    "      id                                               text            label\n",
    "0  34243  @local1025 @njdotcom @GovMurphy Oh, I could ha...  Not hate speech\n",
    "============================================================================\n",
    "\n",
    "'''\n",
    "\n",
    "test_dataframe_working_with = pd.read_csv(\"LOCATION_OF_THE_test_dataframe_working_with.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714653c-1eb7-4183-94ae-cc8117fceccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = test_dataframe_working_with\n",
    "# folds = KFold(n_splits=5)\n",
    "\n",
    "# creating a dictionary to save the classification report.\n",
    "cv_dictionary = dict()\n",
    "\n",
    "# it means how many iteration we will do over the test set.\n",
    "# for printing and saving all the importante report w.r.t the current run\n",
    "run = 0\n",
    "\n",
    "# defines how many iteration you want to do for the current experiment.\n",
    "total_iteration = 5\n",
    "\n",
    "for i in range(total_iteration):\n",
    "    \n",
    "    run += 1\n",
    "    print(f\"===========RUN: {run} starting===========\")\n",
    "    # Cleaning the test dataset\n",
    "    df_test = text_processor.preprocess_dataframe(df_hateval_test)\n",
    "    \n",
    "    # this will take only 5 instances from the test set and perform the model inference\n",
    "    df_test = df_test.loc[:2-1]\n",
    "\n",
    "    '''\n",
    "    getting the batches of batches as it was before\n",
    "    '''\n",
    "    # create an empty list to store the index values\n",
    "    batches_of_batches = []\n",
    "\n",
    "    # loop over the dataframe using iterrows() method\n",
    "    for index, row in df_test.iterrows():\n",
    "        # append the index value to the list\n",
    "        batches_of_batches.append([index])\n",
    "        \n",
    "\n",
    "    if not os.path.exists(f'response_{name_of_experiment}_run_{run}.csv'):\n",
    "        with open(f\"response_{name_of_experiment}_run_{run}.csv\", \"a\", newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Input\", \"Complete Response\", \"Model Output\", \"Date and Time\"])\n",
    "\n",
    "    if not os.path.exists(f'groundtruth_{name_of_experiment}_run_{run}.csv'):\n",
    "        with open(f\"groundtruth_{name_of_experiment}_run_{run}.csv\", \"a\", newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"test-instance-index\",\"groundtruth-text\", \"groundtruth-label\"])\n",
    "\n",
    "\n",
    "    # Go through each batch (it has n instances)\n",
    "    for batch_number, i in enumerate(batches_of_batches):\n",
    "\n",
    "        text_list_gold = list()\n",
    "\n",
    "\n",
    "        # loop through each instances within a batch\n",
    "        for k in i:\n",
    "\n",
    "            # k = index\n",
    "\n",
    "            text_list_gold.append(df_test.loc[k]['text'])\n",
    "            data = [k, df_test.loc[k]['text'], df_test.loc[k]['label']]\n",
    "\n",
    "            # Open the CSV file for writing the ground truth\n",
    "            with open(f\"groundtruth_{name_of_experiment}_run_{run}.csv\", \"a\", newline='', encoding=\"utf-8\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                # Write the data rows\n",
    "                writer.writerow(data)\n",
    "\n",
    "        # Below creating the final template, containing the appended text and the examples that \n",
    "        # are to be classified by the model\n",
    "\n",
    "        # text_list_gold has the text that I want to classify with the model\n",
    "        for text in text_list_gold:\n",
    "            # template += f\"\\nText:{text}\\nLabel:\"\n",
    "            template = create_prompt(text, fourshot=True)\n",
    "        # print(template)\n",
    "\n",
    "        # break\n",
    "\n",
    "        # Note: \n",
    "\n",
    "        '''\n",
    "        In all experiments throughout this paper, for our calls to GPT-3,\n",
    "        we Players_(film)Players_(film)set the temperature to 0.0 and the top_P to 1.0. 1 These settings\n",
    "        serve two purposes. First, they ensure reproducibility, specifically\n",
    "        that GPT-3 will always have the same response given the prompt\n",
    "        we pass it. Second, they minimize the risk that GPT-3 will wander off topic or hallucinate.\n",
    "\n",
    "        Paper: Can GPT-3 Perform Statutory Reasoning?\n",
    "        Link: https://arxiv.org/pdf/2302.06100.pdf\n",
    "\n",
    "        '''\n",
    "\n",
    "        retry_limit = 10  # Maximum number of retries\n",
    "\n",
    "        try_count = 0\n",
    "\n",
    "        while try_count < retry_limit:\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You must reply with either 'Hate speech' or 'Not hate speech' based solely on the linguistic content of the text that you will be asked to classify.\"},\n",
    "                        {\"role\": \"user\", \"content\": template}\n",
    "                    ],\n",
    "                    temperature=0,\n",
    "                )\n",
    "\n",
    "                # If the response is successful, break out of the loop\n",
    "                break\n",
    "\n",
    "            except openai.error.RateLimitError as e:\n",
    "                print(\"Rate limit exceeded. Waiting for 3 minute before retrying...\")\n",
    "                time.sleep(180)  # Wait for 3 minute (adjust as needed)\n",
    "                try_count += 1  # Increment the try count and retry\n",
    "\n",
    "            except Exception as e:\n",
    "                # catch me if you can i.e. catch everything. I am determined to get the model output no matter what - we live only once right?\n",
    "                print(f\"This Exception: {e}\")\n",
    "                print(f\"For this batch, we got the error: {batch_number}\")\n",
    "                print(f\"These are the instances that the model could not create a completion for: {i}\")\n",
    "                print(f\"For this exception {e}, Waiting for 5 minute before retrying...\")\n",
    "                time.sleep(300)  # Wait for 3 minute (adjust as needed)\n",
    "                try_count += 1\n",
    "\n",
    "        if try_count == retry_limit:\n",
    "            print(f\"Reached the maximum number of retries: {retry_limit}. Unable to get a successful response.\\nTherefore using the previous label as the current label for the test text\")\n",
    "\n",
    "        # print(\"something\")\n",
    "        # saving some data\n",
    "        now = datetime.datetime.now()\n",
    "        data = [template, response, response['choices'][0]['message']['content'], now.strftime(\"%Y-%m-%d %H:%M:%S\")]\n",
    "        # Open the CSV file for writing\n",
    "        with open(f\"response_{name_of_experiment}_run_{run}.csv\", \"a\", newline='',encoding=\"utf-8\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            # Write the data rows\n",
    "            writer.writerow(data)\n",
    "        \n",
    "        label = response['choices'][0]['message']['content']\n",
    "        # i[0] is the instance index that is coming from batches_of_batches\n",
    "        instance_label = [(i[0], label)]\n",
    "        try:\n",
    "            with open(f\"modeloutput_{name_of_experiment}_run_{run}.csv\", 'x') as file:\n",
    "                # Create a new Dataframe with the label\n",
    "                df = pd.DataFrame(instance_label, columns=[\"test-instance-index\",\"gpt-label\"])\n",
    "                # Write the DataFrame to the csv file\n",
    "                df.to_csv(f\"modeloutput_{name_of_experiment}_run_{run}.csv\", index=False)\n",
    "        except FileExistsError:\n",
    "            # If the file already exists, append the data to it\n",
    "            with open(f\"modeloutput_{name_of_experiment}_run_{run}.csv\", 'a', encoding=\"utf-8\") as file:\n",
    "                # Create a new DataFrame with the data\n",
    "                df = pd.DataFrame(instance_label, columns=[\"test-instance-index\",\"gpt-label\"])\n",
    "                # Append the DataFrame to the csv file\n",
    "                df.to_csv(file, header=False, index=False)\n",
    "\n",
    "    \n",
    "    # reading the models output and groundtruth for creating the classificaion report\n",
    "\n",
    "    ground_truth = pd.read_csv(f\"groundtruth_{name_of_experiment}_run_{run}.csv\")\n",
    "    model_output = pd.read_csv(f\"modeloutput_{name_of_experiment}_run_{run}.csv\")\n",
    "    \n",
    "    # Ground truth data\n",
    "    y_true = ground_truth[\"groundtruth-label\"]\n",
    "\n",
    "    # Model output data\n",
    "    y_pred = model_output[\"gpt-label\"]\n",
    "\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    \n",
    "    report_dictionary = classification_report(y_true, y_pred, output_dict=True)\n",
    "    #saving each classificaiton report for the current run\n",
    "    cv_dictionary[f'run_{run}'] = report_dictionary\n",
    "    \n",
    "    print(report)\n",
    "    print(\"\\n\")\n",
    "    print(f\"=========Run: {run} Finish ==============\\n\")\n",
    "    print(f\"\\n=====Sleeping for 5 minute before going to the next run=====\\n\")\n",
    "    time.sleep(300)\n",
    "\n",
    "\n",
    "# saving the complete report for each run \n",
    "with open(f\"five_run_report_{name_of_experiment}.json\", \"w\") as f:\n",
    "          json.dump(cv_dictionary, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
