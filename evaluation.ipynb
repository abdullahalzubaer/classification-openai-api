{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f5a04-03c7-4a12-a853-430c5f512ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This code loops through everything that is in the json file that has all the report for\n",
    "5 run and then create another json file with the averages and standard deviation.\n",
    "\n",
    "Things to modify: \n",
    "\n",
    "1. Modify the variable of class_a, class_b according to what class you have.\n",
    "2. Provide the name of the experiment\n",
    "3. Provide the json file i.e. \"json_file_path\"\n",
    "\n",
    "Note:\n",
    "\n",
    "If you have more than one class, you can simply add it as \n",
    "class_c = \"New class\"\n",
    "\n",
    "and add the \"class_c\" as an elemen in the categories list.\n",
    "\n",
    "'''\n",
    "\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "# Some variables\n",
    "\n",
    "# Provide the identfier for the experiment you are trying to evaluate\n",
    "name_of_experiment = \"hatespeech\"\n",
    "class_a = \"Hate speech\"\n",
    "class_b = \"Not hate speech\"\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = f\"five_run_report_{name_of_experiment}.json\"\n",
    "output_file_path = f\"summarized_metric_results_of_{name_of_experiment}.json\"\n",
    "\n",
    "# Open the file in read mode using 'with' statement\n",
    "with open(json_file_path, \"r\") as json_file:\n",
    "    # Load the contents of the file into a dictionary\n",
    "    data = json.load(json_file)\n",
    "\n",
    "metrics = [\"precision\", \"recall\", \"f1-score\"]\n",
    "\n",
    "metric_results = {}\n",
    "\n",
    "categories = [class_a, class_b, \"macro avg\", \"weighted avg\"]\n",
    "\n",
    "for category in categories:\n",
    "    metric_results[category] = {}\n",
    "    for metric in metrics:\n",
    "        metric_list = []\n",
    "        for i in range(1, len(data) + 1):\n",
    "            metric_list.append(data[f'run_{i}'][category][metric])\n",
    "\n",
    "        mean_metric = statistics.mean(metric_list)\n",
    "        stdev_metric = statistics.stdev(metric_list)\n",
    "\n",
    "        metric_results[category][metric] = {\n",
    "            \"mean\": mean_metric,\n",
    "            \"standard_deviation\": stdev_metric\n",
    "        }\n",
    "\n",
    "# Extract the support values for class_a and class_b categories\n",
    "class_a_support = data[\"run_1\"][class_a][\"support\"]\n",
    "class_b_support = data[\"run_1\"][class_b][\"support\"]\n",
    "\n",
    "# Include the support values in metric_results\n",
    "metric_results[class_a][\"support\"] = class_a_support\n",
    "metric_results[class_b][\"support\"] = class_b_support\n",
    "\n",
    "# Calculate average accuracy and standard deviation\n",
    "accuracy_list = [data[f'run_{i}']['accuracy'] for i in range(1, len(data) + 1)]\n",
    "mean_accuracy = statistics.mean(accuracy_list)\n",
    "stdev_accuracy = statistics.stdev(accuracy_list)\n",
    "\n",
    "metric_results[\"accuracy\"] = {\n",
    "    \"mean\": mean_accuracy,\n",
    "    \"standard_deviation\": stdev_accuracy\n",
    "}\n",
    "\n",
    "# Write the result to the output JSON file\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    json.dump(metric_results, output_file, indent=4)\n",
    "\n",
    "print(\"Metric results have been saved to\", output_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
